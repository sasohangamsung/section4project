{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai08_sc4x_송성근.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "캐글 설치"
      ],
      "metadata": {
        "id": "cIi91K6PfwgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "HGxD3h8yfdqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "캐글 키 입력"
      ],
      "metadata": {
        "id": "9COauotQfzIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'sosohangamsung'\n",
        "os.environ['KAGGLE_KEY'] = 'ee9d9419de6ab91a28058fa4acf092f6'"
      ],
      "metadata": {
        "id": "xciFSqGrfzhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "캐글 데이터 가져오기"
      ],
      "metadata": {
        "id": "NOpxhH3bf3lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification"
      ],
      "metadata": {
        "id": "Y1myQ1YPerYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "압축 해제"
      ],
      "metadata": {
        "id": "e8py-jd9gBEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q gtzan-dataset-music-genre-classification.zip"
      ],
      "metadata": {
        "id": "rDcU9IJoe0Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**음향데이터를 librosa를 활용하여 분석을 진행할 수 있게 수치화**\n",
        "<br>\n",
        "<br>\n",
        "y: 소리가 떨리는 세기(진폭)를 시간 순서대로 나열한 것\n",
        "<br>\n",
        "sr : sampling rate = 1초당 샘플의 개수, 단위 Hz 또는 KHz"
      ],
      "metadata": {
        "id": "jWx6oFa2gGZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "y, sr = librosa.load('Data/genres_original/reggae/reggae.00036.wav')\n",
        "\n",
        "print(y)\n",
        "print(len(y))\n",
        "print('Sampling rate (KHz): %d' % sr)\n",
        "print('Audio length (seconds): %.2f' % (len(y) /sr))"
      ],
      "metadata": {
        "id": "HTdZebssfNoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2D 음파 그래프"
      ],
      "metadata": {
        "id": "6O5t5YVJgSG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.waveplot(y=y, sr=sr)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2RY_PZqvjWFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fourier fit_transform**\n",
        "<br>\n",
        "<br>\n",
        "- 시간 영역 데이터를 주파수 영역으로 변경\n",
        "<br>\n",
        "- y축 : 주파수(로그 스케일)\n",
        "<br>\n",
        "- color축 : 데시벨(진폭)"
      ],
      "metadata": {
        "id": "za4R53A5hOoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "D = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))\n",
        "\n",
        "print(D.shape)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(D)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "65omhDjNnnH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "77RU3ESCj-yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spectogram\n",
        "<br>\n",
        "- 시간에 따른 신호 주파수의 스펙트럼 그래프\n",
        "- 다른 이름 : Sonographs, Voiceprints, Voicegrams"
      ],
      "metadata": {
        "id": "LZy9mJ0AhnQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DB = librosa.amplitude_to_db(D, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.specshow(DB, sr=sr, hop_length=512, x_axis='time', y_axis='log')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x4IJ_Tpbn-oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mel Spectogram**\n",
        "<br>\n",
        "- (인간이 이해하기 힘든) Spectogram의 y축을 Mel Scale로 변환한 것(Non-linear transformation)\n",
        "<br>\n",
        "- Mel Scale: https://newsight.tistory.com/294"
      ],
      "metadata": {
        "id": "72rwAI-1hzA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 레게\n",
        "\n",
        "S = librosa.feature.melspectrogram(y, sr=sr)\n",
        "S_DB = librosa.amplitude_to_db(S, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.specshow(S_DB, sr=sr, hop_length=512, x_axis='time', y_axis='log')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Eh9ZWgczoeyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래식\n",
        "y1, sr1 = librosa.load('Data/genres_original/classical/classical.00036.wav')\n",
        "y1, _ = librosa.effects.trim(y1)\n",
        "\n",
        "S1 = librosa.feature.melspectrogram(y1, sr=sr1)\n",
        "S_DB1 = librosa.amplitude_to_db(S1, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.specshow(S_DB1, sr=sr1, hop_length=512, x_axis='time', y_axis='log')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QJ0tR9PGo89M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**오디오 특성 추출**\n",
        "<br>\n",
        "<br>\n",
        "음악의 속도(Tempo) 파악하기"
      ],
      "metadata": {
        "id": "6_efpucAiRMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempo, _ = librosa.beat.beat_track(y, sr=sr)\n",
        "tempo1, _ = librosa.beat.beat_track(y1, sr=sr1)\n",
        "\n",
        "print(tempo)\n",
        "print(tempo1)"
      ],
      "metadata": {
        "id": "gKv7kvp-p2Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero Crossing Rate**\n",
        "<br>\n",
        "- 음파가 양에서 음으로 또는 음에서 양으로 바뀌는 비율"
      ],
      "metadata": {
        "id": "DYAUGY9NiajW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_crossings = librosa.zero_crossings(y, pad=False)\n",
        "zero_crossings1 = librosa.zero_crossings(y1, pad=False)\n",
        "\n",
        "print(sum(zero_crossings))\n",
        "print(sum(zero_crossings1))"
      ],
      "metadata": {
        "id": "Q5uqFdCaqQIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확대(레게)\n",
        "\n",
        "n0 = 9000\n",
        "n1 = 9040\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(y[n0:n1])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wwJf6yHFqiC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확대(클래식)\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(y1[n0:n1])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UuM2VMOQqwaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Harmonic and Percussive Components\n",
        "<br>\n",
        "<br>\n",
        "- Harmonics: 사람의 귀로 구분할 수 없는 특징들 (음악의 색깔)\n",
        "<br>\n",
        "- Percussives: 리듬과 감정을 나타내는 충격파"
      ],
      "metadata": {
        "id": "bXPPh-sMirs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#레게\n",
        "y_harm, y_perc = librosa.effects.hpss(y)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(y_harm, color='b')\n",
        "plt.plot(y_perc, color='r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2RboqFSiqyMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#클래식\n",
        "y_harm1, y_perc1 = librosa.effects.hpss(y1)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(y_harm1, color='b')\n",
        "plt.plot(y_perc1, color='r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mxQlqgJlFjxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spectral Centroid**\n",
        "<br>\n",
        "- 소리를 주파수로 표현했을 때, 주파수의 가중평균을 계산하여 소리의 '무게중심'이 어딘지를 알려주는 지표\n",
        "<br>\n",
        "- 예를 들어, 블루스 음악은 무게중심이 가운데 놓여있는 반면, 메탈 음악은(끝 부분에 달리기 때문에) 노래의 마지막 부분에 무게중심이 실린다."
      ],
      "metadata": {
        "id": "Vs1GlM5zwrdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#레게\n",
        "spectral_centroids = librosa.feature.spectral_centroid(y, sr=sr)[0]\n",
        "\n",
        "frames = range(len(spectral_centroids))\n",
        "\n",
        "t = librosa.frames_to_time(frames)\n",
        "\n",
        "import sklearn\n",
        "def normalize(x, axis=0) :\n",
        "    return sklearn.preprocessing.minmax_scale(x, axis=axis)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.waveplot(y, sr=sr, alpha=0.5, color='b')\n",
        "plt.plot(t, normalize(spectral_centroids), color='r')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6lZMHqxlFr9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#클래식\n",
        "spectral_centroids1 = librosa.feature.spectral_centroid(y1, sr=sr1)[0]\n",
        "\n",
        "frames1 = range(len(spectral_centroids1))\n",
        "\n",
        "t1 = librosa.frames_to_time(frames1)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.waveplot(y1, sr=sr1, alpha=0.5, color='b')\n",
        "plt.plot(t1, normalize(spectral_centroids1), color='r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PbNuibY-GgqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spectral Rolloff**\n",
        "<br>\n",
        "- 신호 모양을 측정한다.\n",
        "<br>\n",
        "- 총 스펙트럴 에너지 중 낮은 주파수(85% 이하)에 얼마나 많이 집중되어 있는가"
      ],
      "metadata": {
        "id": "P3xMC_X8yVGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#레게\n",
        "spectral_rolloff = librosa.feature.spectral_rolloff(y, sr=sr)[0]\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.waveplot(y, sr=sr, alpha=0.5, color='b')\n",
        "plt.plot(t, normalize(spectral_rolloff), color='r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r-vFhbWfGoY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#클래식\n",
        "spectral_rolloff1 = librosa.feature.spectral_rolloff(y1, sr=sr1)[0]\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.waveplot(y1, sr=sr1, alpha=0.5, color='b')\n",
        "plt.plot(t, normalize(spectral_rolloff1), color='r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "41ClFMpIHaFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mel_Frequency Cepstral Coefficients (MFCCs)**\n",
        "<br>\n",
        "- MFCCs는 특징들이 작은 집합(약 10-20)으로 스텍프럴 포곡선의 전쳊넉인 모양을 축약하여 보여준다.\n",
        "<br>\n",
        "- 사람의 청각 구조를 반영하여 음성 정보 추출\n",
        "<br>\n",
        "- https://tech.kakaoenterprise.com/66"
      ],
      "metadata": {
        "id": "VibAESrOzhDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#레게\n",
        "\n",
        "mfccs = librosa.feature.mfcc(y, sr=sr)\n",
        "mfccs = normalize(mfccs, axis=1)\n",
        "\n",
        "print('mean: %.2f' % mfccs.mean())\n",
        "print('var: %.2f' % mfccs.var())\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RkGU6gNGHebX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#클래식\n",
        "mfccs1 = librosa.feature.mfcc(y1, sr=sr1)\n",
        "mfccs1 = normalize(mfccs1, axis=1)\n",
        "\n",
        "print('mean: %.2f' % mfccs1.mean())\n",
        "print('var: %.2f' % mfccs1.var())\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.specshow(mfccs1, sr=sr1, x_axis='time')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vdn5tkbnH4SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chroma Frequencies\n",
        "<br>\n",
        "- 크로마 특징은 음악의 흥미롭고 강렬한 표현이다.\n",
        "<br>\n",
        "- 크로마는 인간 청각이 옥타브 차이가 나는 주파수를 가진 두 음을 유사음으로 인지한다는 음악이론에 기반한다\n",
        "<br>\n",
        "- 모든 스펙트럼을 12개의 Bin으로 표현한다.\n",
        "- 12개의 Bin은 옥타브에서 12개의 각기 다른 반음(Semitones=Chroma)을 의미한다."
      ],
      "metadata": {
        "id": "KbIzq58G0dFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#레게\n",
        "\n",
        "chromagram = librosa.feature.chroma_stft(y, sr=sr, hop_length=512)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=512)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qJYZ_CmZIA7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#클래식\n",
        "\n",
        "chromagram1 = librosa.feature.chroma_stft(y1, sr=sr1, hop_length=512)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "librosa.display.specshow(chromagram1, x_axis='time', y_axis='chroma', hop_length=512)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sCuCszRlNAKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 프레임 불러오기**"
      ],
      "metadata": {
        "id": "zmhjPxzO1sgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Data/features_3_sec.csv')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "auYUehZ-NIB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리"
      ],
      "metadata": {
        "id": "7hCOff701vuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['filename', 'length', 'label'])\n",
        "y = df['label']\n",
        "\n",
        "scaler = sklearn.preprocessing.MinMaxScaler()\n",
        "np_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X = pd.DataFrame(np_scaled, columns=X.columns)\n",
        "\n",
        "X.head()"
      ],
      "metadata": {
        "id": "SuPsFwZrNkO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train, test set 분리"
      ],
      "metadata": {
        "id": "wgZqV9bH1yc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2021)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "o73UOIW2OFBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "random forest 학습 및 평가"
      ],
      "metadata": {
        "id": "AMdfTfClOCjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=100)\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "y_pred = forest.predict(X_test)\n",
        "\n",
        "print('정확도 : %.2f' % metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "cY4vSgrfOC6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "xgb boost 학습 및 평가"
      ],
      "metadata": {
        "id": "7TYy5pnr101m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "y_preds = xgb.predict(X_test)\n",
        "\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_preds))"
      ],
      "metadata": {
        "id": "AxBFHporPF2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "confusion_matrix"
      ],
      "metadata": {
        "id": "Vc_rLBqS164S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(16, 9))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    xticklabels=[\"blues\", \"classical\", \"country\", \"disco\", \"gipgop\", \"jazz\", \"meta\", \"pop\", \"reggae\", \"rock\"],\n",
        "    yticklabels=[\"blues\", \"classical\", \"country\", \"disco\", \"gipgop\", \"jazz\", \"meta\", \"pop\", \"reggae\", \"rock\"]\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JpbBDsdNb9xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_importance = pd.DataFrame([X_test.columns, forest.feature_importances_]).T\n",
        "df_importance.sort_values(1, ascending=False).head(10)"
      ],
      "metadata": {
        "id": "SwBlBuD7cMUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, y_preds)\n",
        "\n",
        "plt.figure(figsize=(16, 9))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    xticklabels=[\"blues\", \"classical\", \"country\", \"disco\", \"gipgop\", \"jazz\", \"meta\", \"pop\", \"reggae\", \"rock\"],\n",
        "    yticklabels=[\"blues\", \"classical\", \"country\", \"disco\", \"gipgop\", \"jazz\", \"meta\", \"pop\", \"reggae\", \"rock\"]\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lYR5N1f8QG33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature_importances"
      ],
      "metadata": {
        "id": "IPIRZ0aE1-BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_importance = pd.DataFrame([X_test.columns, xgb.feature_importances_]).T\n",
        "df_importance.sort_values(1, ascending=False).head(10)"
      ],
      "metadata": {
        "id": "zLSsdMyvVXVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**딮러닝 모델 학습**"
      ],
      "metadata": {
        "id": "yANxsKsA6wGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U keras-tuner"
      ],
      "metadata": {
        "id": "kafAEo2h8mvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import IPython\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import kerastuner as kt"
      ],
      "metadata": {
        "id": "c8sfJmSc-28P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.DataFrame(y_train)"
      ],
      "metadata": {
        "id": "dIwGtSG-AhNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = pd.DataFrame(y_test)"
      ],
      "metadata": {
        "id": "mTremY1sC5lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "enc = OrdinalEncoder()\n",
        "y_train_encoded = enc.fit_transform(y_train)\n",
        "y_test_encoded = enc.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "Rrm1RtM4B581"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rZsh9dSvB5_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu'))\n",
        "Dropout(0.5)\n",
        "model.add(Dense(512, activation='relu'))\n",
        "Dropout(0.5)\n",
        "model.add(Dense(512, activation='relu'))\n",
        "Dropout(0.5)\n",
        "model.add(Dense(512, activation='relu'))\n",
        "Dropout(0.5)\n",
        "model.add(Dense(512, activation='relu'))\n",
        "Dropout(0.5)\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "            loss='sparse_categorical_crossentropy', \n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train_encoded, epochs=500)"
      ],
      "metadata": {
        "id": "JU3TvSgq8kXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,  y_test_encoded)"
      ],
      "metadata": {
        "id": "Z7KNLxozXAG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_30 = pd.read_csv('Data/features_30_sec.csv', index_col='filename')\n",
        "\n",
        "labels = df_30[['label']]\n",
        "df_30 = df_30.drop(columns=['length', 'label'])\n",
        "\n",
        "df_30_scaled = sklearn.preprocessing.scale(df_30)\n",
        "\n",
        "df_30 = pd.DataFrame(df_30_scaled, columns=df_30.columns)\n",
        "\n",
        "df_30.head()"
      ],
      "metadata": {
        "id": "-bEWfLbvV6V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity = cosine_similarity(df_30)\n",
        "\n",
        "sim_df = pd.DataFrame(similarity, index=labels.index, columns=labels.index)\n",
        "\n",
        "sim_df.head()"
      ],
      "metadata": {
        "id": "QRNAICscZmeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_songs(name, n=5):\n",
        "    series = sim_df[name].sort_values(ascending=False)\n",
        "\n",
        "    series = series.drop(name)\n",
        "\n",
        "    return series.head(n).to_frame()\n",
        "\n",
        "find_similar_songs('rock.00000.wav')\n"
      ],
      "metadata": {
        "id": "FMRj0MZtZ2Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mKlogAaHayHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SMBAqtHZaenK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}